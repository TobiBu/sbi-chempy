%                                                                 aa.dem
% AA vers. 9.1, LaTeX class for Astronomy & Astrophysics
% demonstration file
%                                                       (c) EDP Sciences
%-----------------------------------------------------------------------
%
%\documentclass[referee]{aa} % for a referee version
%\documentclass[onecolumn]{aa} % for a paper on 1 column  
%\documentclass[longauth]{aa} % for the long lists of affiliations 
%\documentclass[letter]{aa} % for the letters 
%\documentclass[bibyear]{aa} % if the references are not structured 
%                              according to the author-year natbib style

%
\documentclass{aa}  

%
\usepackage{showyourwork}

\usepackage{graphicx}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{txfonts}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{siunitx}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}       % professional-quality tables
\usepackage{tabularx}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage[options]{hyperref}
% To add links in your PDF file, use the package "hyperref"
% with options according to your LaTeX or PDFLaTeX drivers.
%

\usepackage{tikz}

\usepackage{xcolor}

\newcommand{\todo}[1]{\textcolor{red}{#1}}
\newcommand{\T}[1]{\textcolor{orange}{#1}}
%\newcommand{\U}[1]{\textbf{\textit{\textcolor{blue}{#1}}}}
\newcommand{\U}[1]{\textcolor{black}{#1}}
\usepackage{subfigure}

\begin{document} 


   \title{Inferring Galactic Parameters from Chemical Abundances with Simulation-Based Inference}
   
   \titlerunning{Simulation-Based Inference for Galactic Parameters}
   \authorrunning{T. Buck and B. Günes}

   %\subtitle{Inferring Galactic Parameters from Chemical Abundances with Simulation-Based Inference}

   \author{Tobias Buck\inst{1,2}
          \and
          Berkay Günes\inst{1,2}
          \and
          et al.
          }

   \institute{Interdisciplinary Center for Scientific Computing (IWR), University of Heidelberg,
 Im Neuenheimer Feld 205, D-69120 Heidelberg, Germany
 \and
 Universität Heidelberg, Zentrum für Astronomie, Institut für Theoretische Astrophysik, Albert-Ueberle-Straße 2, D-69120 Heidelberg, Germany\\
 \email{tobias.buck@iwr.uni-heidelberg.de}
             }

   \date{Received Month, XXXX; accepted Month Day, XXXX}

% \abstract{}{}{}{}{} 
% 5 {} token are mandatory
 \abstract
  % context heading (optional)
  % {} leave it empty if necessary  
   {Galactic chemical abundances provide crucial insights into fundamental galactic parameters, such as the high-mass slope of the initial mass function (IMF) and the normalization of Type Ia supernova (SN\,Ia) rates. Constraining these parameters is essential for advancing our understanding of stellar feedback, metal enrichment, and galaxy formation processes. However, traditional Bayesian inference techniques, such as Hamiltonian Monte Carlo (HMC), are computationally prohibitive when applied to the large datasets produced by modern stellar surveys.}
  % aims heading (mandatory)
   {This study aims to leverage simulation-based inference (SBI) as a scalable, robust, and efficient method for constraining galactic parameters from stellar chemical abundances. By focusing on the high-mass IMF slope and SN\,Ia normalization, we aim to demonstrate the advantages of SBI over HMC in terms of speed, scalability, and robustness against model misspecifications.}
  % methods heading (mandatory)
   {We combined a Galactic Chemical Evolution (GCE) model, \texttt{CHEMPY}, with a neural network emulator and a Neural Posterior Estimator (NPE) to train an SBI pipeline. Mock datasets were generated using \texttt{CHEMPY}, including scenarios with mismatched nucleosynthetic yields, and additional tests were conducted on data from a Milky Way-like galaxy taken from a hydrodynamical simulation. SBI results were benchmarked against HMC-based inference, focusing on computational performance, accuracy, and resilience to systematic discrepancies.}
  % results heading (mandatory)
   {Our SBI approach achieves a $\sim1,000\times$ ($\sim72,000\times$) speed-up compared to HMC, reducing inference runtime from $\sim40$ hours for 200 stars to mere minutes for thousands of stars. Inference on $1,000$ stars yielded precise estimates for the IMF slope ($\alpha_{\rm IMF} = -2.296 \pm 0.009$) and SN\,Ia normalization ($\log_{10}(N_{\rm Ia}) = -2.889 \pm 0.010$), deviating by less than 0.04\% from the ground truth. SBI also demonstrated greater robustness to model misspecification than HMC, recovering accurate parameters even with alternate yield tables or data from a cosmological simulation.}
  % conclusions heading (optional), leave it empty if necessary 
   {SBI represents a paradigm shift in galactic chemical enrichment studies, enabling efficient and precise analysis of massive stellar datasets. By outperforming HMC in speed, scalability, and robustness, SBI is poised to become a cornerstone methodology for future spectroscopic surveys, such as 4MOST and WEAVE, facilitating deeper insights into the chemical and dynamical evolution of galaxies.}

%Chemical abundances of stars are able to reveal important galactic parameters, such as the initial mass function high-mass slope and the frequency of type Ia supernovae. Constraining these parameters is of critical importance in order to create realistic hydrodynamical simulations and understand galactic physics. However, so far inference was significantly limited by the computational cost of traditional Bayesian algorithms. Here we present a new method using simulation-based inference (SBI) to circumvent previous limitations and enable inference from massive stellar surveys.
%SBI enables a new approach to the inference of the posterior distribution of Galactic parameters under an intractable likelihood function by utilizing forward simulations of stellar abundance distributions.
%Using SBI we are able to predict global galactic parameters of great accuracy and precision from chemical abundances of multiple stars, faster than conventional methods like Hamiltonian Monte Carlo inference. Our method easily scales to hundred-thousands of stars and beats previous approaches by orders of magnitude in compute time and accuracy.

   \keywords{Galaxies: fundamental parameters --
            Galaxies: stellar content --
             Methods: data analysis --
             Methods: statistical --
             }
\maketitle
%-------------------------------------------------------------------
\section{Introduction}

Understanding the chemical enrichment of galaxies is fundamental to deciphering their formation and evolution. Chemical abundances of stars offer a wealth of information about galactic parameters, such as the high-mass slope of the initial mass function (IMF) and the normalization of Type Ia supernova (SN\,Ia) rates. These parameters critically influence the production of heavy elements \citep[e.g.][]{2005A&A...430..491R,2015MNRAS.449.1327V,2015MNRAS.451.3693M}, stellar feedback, and star formation histories, making their accurate determination essential for realistic hydrodynamical simulations of galaxy formation \citep[e.g.][]{Sawala2016,Hopkins2018,Pillepich2018,Buck2020,Buck2020c,Buck2021,Font2020,Agertz2021}. Despite their importance, constraining these parameters has proven challenging due to limited observational data and the computational demands of traditional inference techniques.

For example, a range of high-mass IMF slopes have been suggested \citep[Tab.\,7]{2016ApJ...824...82C}, with a steeper-than-canonical slope being suggested by a range of studies \citep[e.g.][]{2015ApJ...806..198W,Rybizki2015,Chabrier2014}. In addition, the IMF slope may itself be not a constant but rather a function of metallicity, introducing further complexity \citep[e.g.][]{2019MNRAS.482..118G,Martin2019}. Similarly, the choice of SN\,Ia delay-time-distribution and normalization plays a crucial role in the enrichment of the ISM \citep[e.g.][]{Buck2021} and is heavily debated \citep{2010ApJ...722.1879M,2012MNRAS.426.3282M,2015ApJ...810..137J}.

Recent advances in stellar spectroscopic surveys, such as APOGEE and GALAH, have produced unprecedented datasets of stellar chemical abundances. These datasets hold the potential to unlock detailed constraints on galactic parameters across diverse environments. However, traditional Bayesian inference methods, such as Markov Chain Monte Carlo (MCMC) and Hamiltonian Monte Carlo (HMC), struggle to scale to these large datasets. Such methods are computationally expensive, requiring hours of runtime for even modest sample sizes, and are susceptible to biases when confronted with high-dimensional posterior distributions.

In this work, we present a novel approach leveraging simulation-based inference \citep[SBI, e.g.][]{Cranmer2020} to address these limitations. SBI bypasses the need for explicit likelihood functions, enabling efficient and scalable inference of galactic parameters directly from simulated stellar abundances. By combining a neural network emulator for the \texttt{CHEMPY} Galactic Chemical Evolution (GCE) model with a Neural Posterior Estimator (NPE), we achieve rapid and robust inference. Unlike HMC, which requires extensive sampling for each dataset, our method amortizes the computational cost during training, allowing subsequent inference to scale seamlessly to larger datasets.

This study focuses on two critical global galactic parameters: 
the high-mass slope of the \citet[Tab.\,1]{2003PASP..115..763C} IMF ($\alpha_{\rm IMF}$) and the SN\,Ia normalization ($\log_{10}(N_{\rm Ia})$), the rate of SN\,Ia explosions per unit mass. We demonstrate the accuracy, scalability, and robustness of SBI through tests on mock datasets generated by \texttt{CHEMPY} \citep{Rybizki_2017}, as well as on data from hydrodynamical simulations. Additionally, we compare our results to those obtained using HMC-based inference on the same datasets \citep[see][]{Philcox_2019}, highlighting SBI's superior performance in terms of speed, precision, and resilience to model misspecification.

The structure of this paper is as follows: In Section~\ref{sec:methods}, we outline the methods used, including the GCE model and SBI framework. Section~\ref{sec: Results} presents our results on both \texttt{CHEMPY} and IllustrisTNG \citep{Pillepich2018} mock data, emphasizing SBI's advantages over traditional approaches. Finally, in Section~\ref{sec: discussion}, we discuss the broader implications of our findings and outline potential future applications, before concluding in Section~\ref{sec: conclusion}.




\textcolor{red}{to be adapted... especially the zenodo link\\
Finally, we publicly release all of our code to reproduce the results of this manuscript via GitHub\footnote{URL: {\url{https://github.com/TobiBu/sbi-chempy}}}and refer to Appendix \ref{sec:appendix_code_and_data} for an overview of our code and structure. All our datasets and network weights are publicly available on Zenodo.\footnote{URL: \url{https://zenodo.org/record/8375344}}}

\begin{figure*}[]
     \centering
     %\vspace{-.25cm}
     \includegraphics[width=1\linewidth]{figures/sbi_overview.png}
     \vspace{-.5cm}
     \caption{SBI flow chart. From a set of priors we simulate a sample of stellar abundances using \texttt{CHEMPY} \citep{Rybizki_2017,Philcox_2019} which we use to train a \emph{neural network} emulator to speed up the data generation process. Using the \emph{neural network} emulator we produce training data to train the Neural Density Estimator. With this we infer the posterior distribution of the model parameters from a single star. Repeating that for $N_{\rm stars}$ from the same galaxy gives an accurate fit of the IMF slope and Type Ia supernovae normalization.}
     \label{fig:flowchart}
\end{figure*}

% %--------------------------------------------------------------------
\section{Methods}
\label{sec:methods}

In order to establish our new method based on SBI we need two ingredients: A simulator (in our case a GCE model) that simulates observational data from a set of model parameters (in our case the IMF slope and the Type Ia supernovae normalization) and a flexible way of parametrizing the posterior density conditioned on the observation in order to perform our inference (see Fig. \ref{fig:flowchart} for a schematic visual representation of our method). In the next subsections we describe both ingredients in detail.

\subsection{Galactic chemical evolution models}
Our simulator is based on the \texttt{CHEMPY} model \citep{Rybizki_2017}. \texttt{CHEMPY} is a simple GCE model that is able to predict stellar chemical abundances throughout cosmic time by using published nucleosynthetic yield tables for three key processes (SN\,Ia and SN\,II explosions and AGB stellar feedback) and a small number of parameters controlling simple stellar populations (SSPs) and ISM physics. We refer to the initial \texttt{CHEMPY} paper \citep{Rybizki_2017} for the details of the model.

In particular, we are using the \texttt{CHEMPYScoring} module \citep{Philcox_2018} publicly available as the \texttt{CHEMPYMulti} \citep{Philcox_2019}\footnote{\href{https://github.com/oliverphilcox/ChempyMulti}{github.com/oliverphilcox/ChempyMulti}} package a further development of the original \texttt{CHEMPY} model. 

\paragraph{\texttt{CHEMPY} parameters}
In this work, we allow six \texttt{CHEMPY} parameters to vary freely (see also Tab.\,\ref{tab:priors}). These can be categorized into three groups:
\begin{enumerate}
     \item $\vec\Lambda$: \textbf{Global Galactic Parameters} describe SSP physics and comprise the high-mass \citet{2003PASP..115..763C} IMF slope, $\alpha_\mathrm{IMF}$, and (logarithmic) Type Ia SN normalization, $\log_{10}(N_\mathrm{Ia})$. We treat these as star-independent and assume them to be constant across galactic environments and cosmic time\footnote{Whilst $\log_{10}(N_\mathrm{Ia})$ is constant with respect to time by definition, it being simply a normalization constant, there is some evidence for $\alpha_\mathrm{IMF}$ varying as a function of time or metallicity \citep{Chabrier2014,2016MNRAS.462.2832C,2019MNRAS.482..118G,Martin2019}.}. 
     We adopt the same broad priors as \citep{Philcox_2019} for these variables (see also Tab.\ref{tab:priors}). 
     %
     \item $\{\vec\Theta_i\}$: \textbf{Local Galactic Parameters} describe the local physics of the ISM and are hence specific to each stellar environment, indexed by $i$. As defined in \citep{Rybizki_2017}, these include the star-formation efficiency (SFE), $\log_{10}(\text{SFE})$, the peak of the star formation rate (SFR), $\log_{10}(\mathrm{SFR}_\mathrm{peak})$, and the fraction of stellar outflow that is fed to the gas reservoir, $\mathrm{x}_\mathrm{out}$. We adopt broad priors for all parameters and, as in \citep{Philcox_2019}, fix the SN\,Ia delay-time distribution, $\log_{10}(\tau_{\rm Ia})$, to $\log_{10}(\tau_{\rm Ia})=-0.80$ \citep[see also][]{Philcox_2018}.
     %
     \item $\{T_i\}$: \textbf{Stellar Birth-Times}. Time in Gyr at which a given star is formed from the ISM. We assume that its proto-stellar abundances match the local ISM abundances at $T_i$.
\end{enumerate}

The separability of local (ISM) parameters and global (SSP) parameters is motivated by recent observational evidence: \citet{2019arXiv190710606N} find that the elemental abundances of red clump stars belonging to the thin disk can be predicted almost perfectly from their age and [Fe/H] abundance. This implies that the key chemical evolution parameters affecting the elemental abundances (SSP parameters and yield tables) are held fixed, whilst ISM parameters vary smoothly over the thin disk \citep[which offsets the metallicity for different galactocentric radii, e.g.][for a simulated example]{Buck2020, Wang2024}. Similarly \cite{2019ApJ...874..102W} find that ISM parameter variations are deprojected in the [X/Mg] vs [Mg/H] plane (their Fig.\,17) and that abundance tracks in that space are independent of the stellar sample's spatial position within the Galaxy (their Fig.\,3).

Following \citet{Philcox_2019}, to avoid unrealistic star formation histories (that are very `bursty' for early stars), we additionally require that the SFR (parametrized by a $\Gamma$ distribution with shape parameter $a=2$) at the maximum possible stellar birth-time ($13.8$\,Gyr) should be at least 5\% of the mean SFR, ensuring that there is still a reasonable chance of forming a star at this time-step. This corresponds to the constraint $\log_{10}\left(\mathrm{SFR}_\mathrm{peak}\right)>0.294$. For this reason, a truncated Normal prior will be used for the SFR parameter. Furthermore, we constrain $T_i$ to the interval $[1,13.8]$\,Gyr (assuming an age of the Universe of 13.8\,Gyr), ignoring any stars formed before $1$\,Gyr, which is justified as these are expected to be rare.


\begin{tiny}
\begin{table*}
\begin{minipage}{\textwidth}
\begin{center}
\caption{Free \texttt{CHEMPY} parameters for each star, with their prior values and Gaussian widths. Stellar birth-times are set for each star individually from a Uniform prior, based on realistic age estimates.}
\begin{tabularx}{\textwidth}{ >{\raggedleft}p{2.2cm}p{6.5cm}|c c }
Parameter & Description & $\overline{\theta}_\mathrm{prior}\pm\sigma_\mathrm{prior}$ & Prior from: \\

\hline
\multicolumn{4}{c}{$\vec{\Lambda}$: \textit{Global stellar (SSP) parameters}}\\
\hline
$\alpha_\mathrm{IMF}$ & High-mass slope of the \citep{2003PASP..115..763C} IMF & $-2.3\pm0.3$ & \citep[Tab.\,1]{2003PASP..115..763C} \\
  
$\log_{10}\left(N_\mathrm{Ia}\right)$ & Number of SN\,Ia per $\mathrm{M}_\odot$ over 15\,Gyr & $-2.89\pm0.3$ & \citep[Tab.1\,]{2012PASA...29..447M}\\
  
\hline
\multicolumn{4}{c}{$\vec{\Theta}_i$: \textit{Local ISM parameters}}\\
  
\hline
$\log_{10}\left(\mathrm{SFE}\right)$ & Star formation efficiency governing gas infall & $-0.3\pm0.3$ & \citep{2008AJ....136.2846B}\\
  
$\log_{10}\left(\mathrm{SFR}_\mathrm{peak}\right)$ & SFR peak in Gyr (scale of $k=2$ $\Gamma$-distribution) & $0.55\pm0.1$ & \citep[fig.\,4b]{2013ApJ...771L..35V}\\
  
x$_\mathrm{out}$ & Stellar feedback fraction & $\phantom{-}0.5\pm0.1$ & \citep[Tab.\,1]{Rybizki_2017}\\
  
\hline
\multicolumn{4}{c}{$T_i$: \textit{Timescale}}\\
 
\hline
$T_i$ & Time of stellar birth in Gyr & [$1$,$13.8$] & Observations

\label{tab:priors}
\end{tabularx}
\end{center}
\end{minipage}
\end{table*}
\end{tiny}

\paragraph{Nucleosynthetic yield tables}
We adopt the same nucleosynthetic yield tables as in \citep{Philcox_2019}, see their Sec.~2.2 for more details.
To test our method, we aim further at inferring parameters from a sample of stars taken from a hydrodynamical simulation of a MW type galaxy which we take from the IllustrisTNG project \citep{Pillepich2018}. To ensure maximal compatibility with TNG, we adopt their nucleosynthetic yield tables in \texttt{CHEMPY}, for enrichment by SN\,Ia, SN\,II and AGB stars. The utilized yields are summarized in Tab.\,\ref{tab:chempy_TNG_yields}, matching \citet[Tab.\,2]{2018MNRAS.473.4077P}, and we note that the SN\,II yields are renormalized such that the IMF-weighted yield ratios at each metallicity are equal to those from the \citet{2006ApJ...653.1145K} mass range models alone. \texttt{CHEMPY} uses only net yields, such that they provide only newly synthesized material, with the remainder coming from the initial SSP composition. These tables may not well-represent true stellar chemistry, and the effects of this mismatch are examined in Sec.\,\ref{subsec:mocks_wrong_yield} by performing inference using an alternative set of yields that does not match the yield set of the training data. For the analysis of observational data, we would want to use the most up-to-date yields, such as \citet{2016ApJ...825...26K} AGB yields, and carefully choose elements which are known to be well reproduced by our current models (e.g. shown by \citet{2019ApJ...874..102W,2019arXiv190806113G}), though this is not appropriate in our context. To facilitate best comparison with Ilustris TNG, we further set the maximum SN\,II mass as $100\,\mathrm{M}_\odot$ (matching the IMF upper mass limit), adopt stellar lifetimes from \citet{portinari} and do not allow for any `hypernovae' \citep[in contrary to][]{2018ApJ...861...40P}).

\begin{table}[]
\caption{Nucleosynthetic yield tables used in this analysis, matching those of the TNG simulation \citep[Tab.\,2]{2018MNRAS.473.4077P}.}
     \centering
     \begin{tabular}{c|c}
       Type & Yield Table \\
        \hline
         SN\,Ia & \citet{1997NuPhA.621..467N}\\
         SN\,II & \citet{2006ApJ...653.1145K,portinari}\\
         AGB & \citet{2010MNRAS.403.1413K,2014MNRAS.437..195D};\\
         & \citet{2014ApJ...797...44F}
     \end{tabular}
 \label{tab:chempy_TNG_yields}
 \end{table}


\paragraph{Chemical elements}
In our analysis we only track nine elements: C, Fe, H, He, Mg, N, Ne, O and Si since these are the only elements traced by TNG. We principally compare the logarithmic abundances [X/Fe] and [Fe/H] defined by 
\begin{equation}
     [\mathrm{X}/\mathrm{Y}] = \log_{10}(N_\mathrm X/N_\mathrm Y)_\mathrm{star} - \log_{10}(N_\mathrm X/N_\mathrm Y)_\odot
\end{equation}
for number fraction $N_\mathrm X$ of element X. Here $\odot$ denotes the solar number fractions of \citet{2009ARA&A..47..481A}. This uses H for normalization, thus we are left with $n_\mathrm{el}=8$ independent elements which must be tracked by \texttt{CHEMPY}\footnote{In observational contexts, it may be more appropriate to compute abundances relative to Mg rather than Fe, as in \citep{2019ApJ...874..102W}, since Mg is only significantly produced by SN\,II and hence a simpler tracer of chemical enrichment.}. 

With these modifications, \texttt{CHEMPY} allows for fast prediction of TNG-like chemical abundances for a given set of galactic parameters. It is important to note that the two GCE models have very different parametrizations of galactic physics, with TNG including vastly more effects, thus it is not certain \textit{a priori} how useful \texttt{CHEMPY} will be in emulating the TNG simulation, although its utility was partially demonstrated in \citet{2018ApJ...861...40P}. However,  such a test is necessary to prepare for an inference on real data.


\subsection{Neural network emulator for \texttt{CHEMPY}}
Despite the simplifications made by the GCE model \texttt{CHEMPY}, the run-time of \texttt{CHEMPY} and the high-dimensionality of the parameter space incurs some difficulties when sampling the distribution of the global parameters $\vec\Lambda = \{\alpha_\mathrm{IMF},\log_{10}(N_\mathrm{Ia})\}$. 
To alleviate this, we follow \cite{Philcox_2019} and implement a \textit{neural network} (NN) emulator of the \texttt{CHEMPY} simulator. We design the NN as a simple feed-forward neural network with 2 hidden layers and 100 neurons in the first and 40 neurons in the second layer. The NN is trained on $\sim100,000$ data points and validated on $\sim50,000$ additional data points created with \texttt{CHEMPY} using a uniform prior over the $5\sigma$-range of the original Gaussian prior stated in table~\ref{tab:priors}. The batch size is set to 64 and the learning rate is set to 0.001. We train for 20 epochs using a schedule free optimizer \citep{schedulefree}. 
Training this tiny emulator takes about 200s on the CPU.

In essence, instead of computing the full model for each input parameter set, we pass the parameters to the NN which predicts the output abundances to high accuracy. As already argued in \cite{Philcox_2019} this has two benefits;
\begin{enumerate}
    \item \textbf{Speed:} The run-time of the \texttt{CHEMPY} function is $\sim1$\,s per input parameter set, which leads to very slow generation of training data for SBI. With the NN emulator, this reduces to $\sim5\times10^{-5}$\,s, and is trivially parallelizable, unlike \texttt{CHEMPY}.
    \item \textbf{Differentiability:} The NN is written in pytorch which allows for automatic differentiation. Additionally the NN has a simple closed-form analytic structure \citep[described in the appendix of][]{Philcox_2019}, unlike the complex \texttt{CHEMPY} model. This allows it to be differentiated, so one can use it to sample via advanced methods such HMC as done in \citep{Philcox_2019}.
\end{enumerate}

Despite the additional complexity introduced by using multiple stellar data-points, our NN simply needs to predict the birth-time abundances for a single star (with index $i$) given a set of six parameters; $\{\vec\Lambda,\vec\Theta_i,T_i\}$. The same NN can be used for all $n_\mathrm{stars}$ stars (and run in parallel), reducing a set of $n_\mathrm{stars}$ runs of \texttt{CHEMPY} to a single matrix computation. With the above network parameter choices, the NN predicts abundances with an absolute percentage error of \variable{output/ape_NN.txt}, which is far below typical observational errors and even smaller away from the extremes of parameter space (see Fig.~\ref{fig:ape_NN}). In fact, we will add additional observational uncertainty to our mock observational data later during training of the neural posteriro estimater network. 

Our NN emulator is publicly available on the github repository accompanying this manuscript \href{https://github.com/TobiBu/sbi-chempy/blob/main/src/scripts/train_torch_chempy.py}{https://github.com/TobiBu/sbi-chempy/blob/main/src/scripts/train\_torch\_chempy.py} with pre-trained NN weights available on zenodo \href{https://zenodo.org/records/14507134}{https://zenodo.org/records/14507134}.

\begin{figure}[]
     \centering
     \includegraphics[width=\columnwidth]{figures/ape_NN.pdf}
     \vspace{-.5cm}
     \caption{Cumulative absolute percentage error of the NN emulator for the \texttt{CHEMPY} simulator. The orange histogram shows the cumulative distribution of percentage errors with the vertical dashed line indicating the median and the vertical dotted lines indicating the first and third quartile. The box plot on the top of the plot extends from the first quartile to the third quartile of the data, with a line at the median. The whiskers extend from the box to the farthest data point lying within $1.5\times$ the inter-quartile range from the box. The NN predicts abundances with an absolute percentage error far below typical observational errors.}
     \label{fig:ape_NN}
     \script{train_torch_chempy.py}
\end{figure}


\subsection{Bayesian model}
\texttt{CHEMPY} effectively is a Bayesian model for stellar abundances given a set of parameters $\{\Vec{\Lambda},\Vec{\Theta},T\}$ and \citet{Philcox_2019} extended the \texttt{CHEMPY} framework to be able to model multiple stellar data-points. Consider a given star with index $i$ that is born in some region of the ISM. This star will carry its own set of parameters $\{\Vec{\Lambda},\Vec{\Theta}_i,T_i\}$, where $\Vec{\Lambda}$ are star independent and hence taken to be global parameters while the ISM parameters $\Vec{\Theta}_i$ and the birth-time $T_i$ are star specific. Using \texttt{CHEMPY} (or the trained neural network emulator) we can easily model the set of $n_\mathrm{el}$ chemical abundances $\{X_i^j\}$ for the $i$-th star as: 
\begin{equation}\label{eq:chempy_function}
\{X_i^j\} = \texttt{CHEMPY}(\Vec{\Lambda},\Vec{\Theta}_i,T_i),
\end{equation}
where $j$ indexes the chemical element. 
These model abundances can then be compared against observations, with measured abundances $d_i^j$ and corresponding Gaussian errors $\sigma_{i,\mathrm{obs}}^j$ jointly denoted as $D_i=\{d_i^j,\sigma_{i,\mathrm{obs}}^j\}$.

\paragraph{Posteriors for Galactic parameters}
As stated in \citet{Philcox_2019} the full posterior for this case is given by 
\begin{eqnarray}\label{eq:posterior}
    \mathbb{P}(\vec\Lambda,\{\vec\Theta_i\},\{T_i\}|\{D_i\}) &\propto&  \left[\prod_{i=1}^{n_\mathrm{star}}p_{\vec\Theta}(\vec\Theta_i)p_{T_i}(T_i)\right]
    \times p_{\vec\Lambda}(\vec\Lambda)\\
    \nonumber
    &\times& \mathcal{L}(\{D_i\}|\vec\Lambda,\{\vec\Theta_i\},\{T_i\})
\end{eqnarray}
where $p_V(V_i)$ is the prior on variable $V_i$ (belonging to the set $V$).

In order to determine the optimal values of the global galactic parameters ($\Vec{\Lambda}$) one has to sample the posterior of Eq.~\ref{eq:posterior}. In practice this is a costly computation, since even with advanced techniques such as HMC sampling the posterior can only be evaluated for a small set of stars ($\lesssim200$) and requires long compute times \citep[$\sim40$ hours][]{Philcox_2019}.
%
However, recent advances in implicit-likelihood inference or SBI \citep{Cranmer2020} offer another very efficient approach to approximate the posterior (see next paragraph for more details). These methods train a neural conditional density estimator to represent the conditional posterior, $\mathbb{P}(\vec\Lambda|\{D_i\})$, which can be very efficiently evaluated given observational data $\{D_i\}$.

In particular, if we marginalize over the star specific parameters and solely focus on the global parameters $\Vec{\Lambda}$ we can make the assumption that individual observations of stars are identically and independently distributed (i.i.d.) and factorize the joint posterior from above to simply express it as:  %
\begin{eqnarray}
\mathbb{P}(\vec\Lambda|\{D_i\}) &\propto& 
\mathbb{P}(\vec\Lambda)\mathbb{P}(\{D_i\}|\Lambda)\quad\quad\quad\quad\quad\quad\,\, \text{(Bayes rule)}
\\\nonumber
&=&
\mathbb{P}(\vec\Lambda)\mathbb{P}
(D_1,...,D_{n_\mathrm{star}}|\vec\Lambda)
\\\nonumber
&=& \mathbb{P}(\vec\Lambda)\prod_{j=1}^{n_\mathrm{star}}\mathbb{P}(D_j|\vec\Lambda) \quad\quad\quad\quad\quad\quad\quad\,\,\,\, \text{(i.i.d.)}
\\\nonumber
&\propto& \mathbb{P}(\vec\Lambda) \prod_{j=1}^{n_\mathrm{star}}\frac{\mathbb{P}(\vec\Lambda|D_j)}{\mathbb{P}(\vec\Lambda)} \quad\quad\quad\quad\quad\text{(Bayes rule)}
\\%\nonumber
\label{eq:posterior}
&=& \mathbb{P}(\vec\Lambda)^{1-n_\mathrm{star}}\ \prod_{j=1}^{n_\mathrm{star}}\mathbb{P}(\vec\Lambda|D_j) 
\end{eqnarray}

This factorization of the joint posterior into single star posteriors $\mathbb{P}(\vec\Lambda|D_j)$ has the advantage that we do not need to specify the exact number of observational data points beforehand. We can simply train our neural density estimator on single star observations and then at evaluation time, we simply combine as many posterior estimates as we have observational data.


\paragraph{Simulation-based inference}
In a nutshell, SBI \citep[e.g.][]{Cranmer2020,Papamakarios:2021,Gloeckler2024AllinoneSI} -- also called likelihood free inference within a Bayesian inference framework -- works as follows: given an assumed generative model $\mathcal{M}$ of parameters $\Vec{\theta}$ (in our case a GCE model) and a set of simulated observations of individual stellar abundances $\Vec{X}$ from that model, we train a mapping between the two to estimate the posterior distribution $p$($\Vec{\theta}|\Vec{X}$, $\mathcal{M}$) of the generative model parameters $\Vec{\theta}$ that reproduce the simulated observations $\Vec{X}$. Once this mapping is trained, we can apply it to observations of stellar abundances $\Vec{X_R}$ to infer $p$($\Vec{\theta}|\Vec{X_R}$, $\mathcal{M}$) (see Fig. \ref{fig:flowchart} for a schematic visual representation of our method). Note, we do not need to know anything about $p$($\Vec{\theta}|\Vec{X_R}$, $\mathcal{M}$), we solely need to be able to sample from it.

We use a NPE \cite{zeghal2022neuralposteriorestimationdifferentiable} which utilises the gradients of the generative model $\mathcal{M}$ with a Neural Spline Flow (NSF) \citet{durkan2019neuralsplineflows} containing 20 hidden features and 10 transformation layers for the normalizing flow. The NSF uses as invertible transformation smooth and flexible spline functions to allow efficient sampling. The expressivity of the spline allows the NDE to be capture complex distributions, while also maintaining computational tractability. The final model was selected after extensive hyperparameter tuning, varying: the architecture between NSF, Masked Autoregressive Flow (MAF) \cite{papamakarios2018maskedautoregressiveflowdensity}, and Mask Autoregressive 
Flow with rational-quadratic spline (MAF-RQS), the number of neurons between {10, 20, 50, 100}, and the number of transformations between {1, 5, 10, 30}, optimizing over the test set for both the highest mean log posterior probability and the best calibration as measured by the TARP value \citep{Lemos2023}. For more details on TARP see \ref{sec:sbc} in the appendix.

We train our NPE with $10^5$ data points consisting of $n_{\rm elements}=8$ simulated with the NN emulator described in the previous section with inputs sampled from a uniform prior over the original $5\sigma$-range of the Gaussian priors shown in Tab. \ref{tab:priors} to provide better coverage of the parameter space. Training takes $\sim70$ minutes on an Intel(R) Xeon(R) Platinum 8468V with 192 CPU cores. 
We evaluate the accuracy of the NPE using $5\times10^4$ validation data points from the original \texttt{CHEMPY} simulator. In order to mimic observational noise, we add 5\% observational uncertainties to the abundances simulated with \texttt{CHEMPY} before feeding them to our NPE.
We have made sure that our NPE is well calibrated and posterior distributions are trustable. For more details on simulation-based calibration see appendix \ref{sec:sbc}.

Note, the methods presented here can naturally be extended to any fast and flexible GCE model, not just \texttt{CHEMPY}.


\begin{figure}[]
     \centering
     \includegraphics[width=\columnwidth]{figures/ape_posterior_NPE_C.pdf}
     \vspace{-.5cm}
     \caption{Absolute percentage error of the neural posterior density estimate for a single star. Different colored histograms show the full error distribution for all 6 parameters of interest with the median values highlighted by the vertical dashed lines. The box plots show again the first and third quantiles with the median represented by a vertical line and the whiskers extending from the box to the farthest data point lying within $1.5\times$ the inter-quartile range from the box. The global parameters of main interest for this work are shown by the light blue and red histogram.}
     \label{fig:posterior_APE}
     \script{plot_posterior_APE.py}
\end{figure}

\paragraph{Multi-star inference}
Following eq.~\ref{eq:posterior} we can calculate the joint posterior for a combined inference using abundance observations of multiple stars. For this, we will condition our NPE individually on single star observations and sample the posterior. Then, according to eq.~\ref{eq:posterior} we simply have to multiply individual posteriors and account for the inverse weighting by some power of the prior which we take from table~\ref{tab:priors}. 

This does however present one issue, that since we only have access to samples from the posterior and not the posterior itself it is difficult to evaluate eq.~\ref{eq:posterior}. We circumvent this by approximating each single star posterior by a Gaussian and fit for the parameters of mean and covariance. With this it is straight forward to evaluate eq.~\ref{eq:posterior} analytically. In fact, under our assumption the combined posterior is a product between the prior and the product of multiple Gaussians for the individual star posteriors. The latter product is also a Gaussian with mean $\mathbf{\mu'}$ and variance $\mathbf{\sigma'}$:
\begin{align}
    \mathbf{\mu'} &= \frac{\sum_{i=1}^{N_{stars}} \frac{\mu_i}{\sigma_i^2}}{\sum_{i=1}^{N_{stars}} \frac1{\sigma_i^2}} \\
\mathbf{\sigma'}^2 &= \frac1 {\sum_{i=1}^{N_{stars}} \frac1{\sigma_i^2}}
\end{align}

Further, in our case the prior for the galactic parameters $\Lambda$ is Gaussian as well. Therefore the resulting factorized posterior from eq.~\ref{eq:posterior} is again a Gaussian and can be expressed with mean $\mathbf{\mu}$ and variance $\mathbf{\sigma}$ as:
\begin{align}
\mathbf{\mu} &= \frac{\frac{\mu'}{\sigma'^2}-\frac{(1-N)\mu_ {prior}}{\sigma_ {prior}^2}}{\frac1{\sigma'^2}-\frac{(1-N)}{\sigma_ {prior}^2}} \\
\mathbf{\sigma}^2 &= \frac1 {\frac1{\sigma'^2}-\frac{(1-N)}{\sigma_ {prior}^2}}
\end{align}

Given the tiny and simple neural network that represents our NPE, we note that the above assumption of Gaussianity in each of the single star posteriors not expected to notably increase our pipeline's error. We have further empirically verified that single star posteriors are indeed close to Gaussian.
However, in future work we plan to alleviate this simplification and directly approximate the joint posterior of a multi-star inference.


\section{Results}
\label{sec: Results}

We use our SBI method described in the previous section to infer the global galactic parameters $\alpha_{\rm {IMF}}$ and $\log_{10}(N_{\rm{Ia}})$. In order to demonstrate the performance and robustness of our methods we use three mock data-sets: 
\begin{enumerate}
    \item Mock observations drawn from \texttt{CHEMPY} from the same yield set as the training data for the neural network emulator. With this we ensure to test our training strategy and the performance without any systematic distribution shifts. 
    \item  \texttt{CHEMPY} mock data using a different yield set to test for potential biases through model missspecification in our SBI setup.
    \item Simulated data from a large-scale hydrodynamical simulation taken from the IllustrisTNG suite \citep{Pillepich2018} but with the same yield set as our \texttt{CHEMPY} training data to ensure that we recover the correct parameters even for models with a completely different treatment of ISM physics.
\end{enumerate}

\subsection{\texttt{CHEMPY} Mock Observational Data}
Our analysis uses mock observations drawn from the neural network emulator with fixed values of the global galactic parameters $\alpha_{\rm IMF}=-2.3$ and $\log_{10}(N_{\rm Ia})=-2.89$ and varying local parameters $\vec{\Theta}_i$ using priors from Tab. \ref{tab:priors}. Additionally we draw $T_i$ uniformly in the range $[2,12.8]$ Gyr to minimize overlap with the neural network training birth-time limits when observational uncertainties are included. 
Each set of parameters is passed to our \texttt{CHEMPY} emulator, producing eight true chemical abundances. In order to fully represent observational data, we augment this data with observational uncertainties by adding a Gaussian error of $0.05$ dex for the abundances representative for typical APOGEE data \citep{Majewski2016}.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/CHEMPY_TNG_yields_Nstar_comp.pdf}
    \vspace{-.5cm}
    \caption{Accuracy of inferred global galactic parameters $\alpha_{IMF}$ and $\log_{10}(N_{Ia})$ as a function of number of observed stars, comparing SBI (blue line) to the inferred values using HMC (red line) as done by \cite{Philcox_2019} and the ground truth values (black dashed line). For the SBI analysis we show $1\sigma$ and $2\sigma$ contours while HMC results only show $1\sigma$ statistical uncertainties as reported in Tab.~3 of \citet{Philcox_2019} (blue/red shaded regions). See Sec.~\ref{subsec:chempy_tng} for a full description.}
    \label{fig:CHEMPY_TNG_N_star_analysis}
    \script{chempy_tng_inference.py}
\end{figure*}
\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/CHEMPY_alternative_yields_Nstar_comp.pdf}
    \vspace{-.5cm}
    \caption{Same as Fig.~\ref{fig:CHEMPY_TNG_N_star_analysis} but for the mock data created with a different yield set than the training data. See Sec.~\ref{subsec:mocks_wrong_yield} for a full description.}
    \label{fig:CHEMPY_alt_N_star_analysis}
    \script{chempy_alt_yield_inference.py}
\end{figure*}
\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/TNG_sim_Nstar_comp.pdf}
    \vspace{-.5cm}
    \caption{Same as Fig.~\ref{fig:CHEMPY_TNG_N_star_analysis} but for the mock data taken from an IllustrisTNG Milky Way-like galaxy. See Sec.~\ref{subsec:tng_sim} for a full description.}
    \label{fig:TNG_N_star_analysis}
    \script{tng_inference.py}
\end{figure*}

For each individual observation consisting of the abundance measurements of a single star we sample the posterior estimate for all six parameters $\{\vec\Lambda,\vec\Theta_i,T_i\}$ with 1,000 points. This takes around $0.3s$ for each star, making it extremely fast to infer the parameters of a large amount of stars. Our method takes around $50$ seconds to build a posterior for all six parameters for a dataset size of 1,000 stars (each time sampling the single star posterior with 1,000 points and fitting for the Gaussian parameters). Our combined runtime for the NPE training plus sampling is then 4250 seconds for 1,000 stars hence our methods making it more than $170$ times faster than current HMC methods \citep[cf.][who need $40$h for only 200 stars]{Philcox_2019}. But since our approach is amortized and we do not need to retrain our NPE model each time we want to make an inference, we in fact achieve an inference speed-up of a factor of $\sim14,400$.
Hence, shorter computing times make it feasible to use orders of magnitudes more observations.

\paragraph{Validation through absolute percentage error}
We start evaluating our method by using \texttt{CHEMPY} to produce a mock observational dataset to ensure no systematical shft between training and testing data in terms of physics parameters.

To evaluate our method quantitatively, we compare the posterior mean to the ground truth value for each observation and calculate the absolute percentage error (APE, see Fig.~\ref{fig:posterior_APE}). For a single star observation, our NPE has an APE of \variable{output/global_posterior_APE.txt} when looking at all 6 parameters of interest. If we restrict ourselves to only the global two parameters, $\vec\Lambda = \{\alpha_\mathrm{IMF},\log_{10}(N_\mathrm{Ia})\}$, our NPE achieves an APE of \variable{output/posterior_APE.txt} as we show in Fig.~\ref{fig:posterior_APE}. Looking at Fig.~\ref{fig:posterior_APE} we find that for an individual star the accuracy of the NPE is not particularly high. However, for the global parameters $\vec\Lambda = \{\alpha_\mathrm{IMF},\log_{10}(N_\mathrm{Ia})\}$ we can boost the accuracy by combining the inference for many stars of the same galaxy.

\subsection{Inference on mock data from \texttt{CHEMPY} with TNG yield set}
\label{subsec:chempy_tng}

\begin{figure}
%\vspace{-1.3cm}
    \centering
    \includegraphics[width=\columnwidth]{figures/CHEMPY_TNG_yields.png}
    \vspace{-.25cm}
    \caption{Joint posterior for global galactic parameters $\alpha_{\rm IMF}$ and $\log_{10}(\rm N_{Ia})$ of $1,000$ stars. The ground truth value is shown by the black dot, the posterior mean of the SBI inference is shown with the red star and white and black ellipses show the $1-3\sigma$ contours of our inference. See Sec.~\ref{subsec:chempy_tng} for a full description.}
    \label{fig:CHEMPY_TNG_sbi} 
    \script{chempy_tng_inference.py}
\end{figure}

%
Combining the inference on multiple observed stars gives us higher accuracy and precision of the global galactic parameters $\vec\Lambda$. We therefore perform inference using a range of stars $n\in[1,1000]$ (see Fig. \ref{fig:CHEMPY_TNG_N_star_analysis}) to show how inference accuracy increases with number of observations. We find that in the limit of few stars (less than $\sim100$) SBI shows a larger uncertainties than the HMC results of \citet{Philcox_2019}. But in the limit of large numbers of stars (few hundred) the accuracy and precision is superior compared to HMC. In particular, after using a few tens of stars, the NPE estimate is less biased than the HMC results. 
Finally, given our computational advantage we will be able to use orders of magnitude more stars for our inference.
This is particularly important since sample variances play a large role when using small samples of stars as also noted in \citet{Philcox_2019}.
%

In Fig.~\ref{fig:CHEMPY_TNG_sbi} we show the joint posterior for $\alpha_{IMF}$ and $\log_{10}(N_{Ia})$ for our inference. The red star indicates the ground truth value, the black dot shows our posterior mean and white contours indicate $1-3\sigma$ levels.
%
Using a sample of 1,000 stars we infer \variable{output/CHEMPY_TNG_sbi.txt} which deviates less than $\sim0.04\%$ from the correct value.

Note that our analysis is in principle also able to infer the local parameters $\Vec{\Theta}_i$ and $T_i$. This would allow us to estimate/infer stellar ages as well. However, currently our NPE network is not particularly good at estimating ages from abundances alone. On average our inference for ages results in an APE of $\sim27\%$ which is slightly larger than the observational noise of $20\%$ that we add during the mock up of our data.

In summary, our SBI pipeline is quite capable of correctly and precisely inferring  global parameters of chemical enrichment models from stellar abundance alone when using the same physical model and yield tables as during training. Next, we will check what happens if the training data is generated with a different yield set to that use at inference time.


\subsection{Inference on mock \texttt{CHEMPY} data with incorrect yield set}
\label{subsec:mocks_wrong_yield}

\begin{figure}
%\vspace{-1.3cm}
    \centering
    \includegraphics[width=\columnwidth]{figures/CHEMPY_alternative_yields.png}
    \vspace{-.25cm}
    \caption{Same as Fig.~\ref{fig:CHEMPY_TNG_sbi} but for the mock data created with a different yield set than the training data. See Sec.~\ref{subsec:mocks_wrong_yield} for a full description.}
    \label{fig:CHEMPY_alt_sbi} 
    \script{chempy_alt_yield_inference.py}
\end{figure}

There is an extensive discussion in the literature about stellar nucleosynthesis with various different yield sets proposed \citep[see e.g. discussion in][]{Rybizki_2017}. In fact, any tabulated yield set will differ from reality and during an application of our inference pipeline it will not be clear which tabulated yield set most closely matches reality and hence which should be used.
In order to investigate how sensitive our method is to a model missspecification by using an incorrect yield set, we create another set of mock data using \texttt{CHEMPY} with a different yield set than during training of our NPE. For better cross-comparison we decided to use the same alternative yield set as presented in Tab.~5 of \citep{Philcox_2019}. In short this yield set uses SN Ia yields from \citet{2003NuPhA.718..139T}, SN II yields from \citet{2013ARA&A..51..457N} and AGB yields from \citet{2016ApJ...825...26K}. By choosing this set of yields we have made sure that contributions to all three processes differ by $\mathcal{O}(10\%)$ \citep[see Sec.~6.2 of][for more details]{Philcox_2019}.

\begin{figure}
%\vspace{-1.3cm}
    \centering
    \includegraphics[width=\columnwidth]{figures/TNG_simulation.png}
    \vspace{-.25cm}
    \caption{Same as Fig.~\ref{fig:CHEMPY_TNG_sim_sbi} but for the mock data taken from an IllustrisTNG Milky Way-like galaxy. See Sec.~\ref{subsec:tng_sim} for a full description.}
    \label{fig:CHEMPY_TNG_sim_sbi} 
    \script{tng_inference.py}
\end{figure}

Our mock data generation and inference then follows the one of Sec.~\ref{subsec:chempy_tng}. This means we apply our NPE that we trained on \texttt{CHEMPY} stellar abundances simulated with the Ilustris TNG yield set to a set of stellar abundances simulated with \texttt{CHEMPY} but using the above mentioned alternative yield set. This effectively probes the effect of model missspecification on the inference results.

We show our inference results for this setup for varying number of stars (blue) in Fig.~\ref{fig:CHEMPY_alt_N_star_analysis} comparing again against HMC results (red) from \citet{Philcox_2019}. We see that the SBI results are less biased than the HMC results especially for $\alpha_{\rm IMF}$. In fact with 100 stars HMC inferences are about \textcolor{red}{calculate value} $\sigma$ away from the ground truth value for $\alpha_{\rm IMF}$ and $\log_{10}(N_{\rm Ia})$, respectively. Again, the joint posterior is shown in Fig.~\ref{fig:CHEMPY_alt_sbi} and shows that while individually parameter inferences look good, jointly taken the SBI results are on the edge of being $3\sigma$ away from the ground truth.

Nevertheless, the performance of our inference is still very good. We see that an increasing number of observations helps to decrease the models uncertainty just as before. However, we also note that our inference is now slightly biased as the observational data does not match the training data. Looking at Fig.~\ref{fig:CHEMPY_alt_sbi} we see that our inference is still consistent with the ground truth within the $3\sigma$ levels. Comparing this to the HMC results, we see that SBI is performing much better when the model is misspecified and leads to significantly less biased results. This is next to drastically reduced compute times -- another a key advantage of our SBI method compared to more standard approaches such as HMC.

In an accompanying paper we more closely investigate measures of model misspecification and inference of best fitting models next to just parameter inference.  

\subsection{Inference on mock data from the IllustrisTNG simulation}
\label{subsec:tng_sim}

As a GCE code, \texttt{CHEMPY} is a one-zone model with simplified ISM physics that only approximately describes star formation and feedback as well as metal mixing in the ISM.
In the parametrization of \texttt{CHEMPY} as used here, we can assign each star to its own ISM environment, but we cannot exchange gas between environments and do not model sudden star formation or infall events. Hence, this section is dedicated to investigate whether this significantly biases our inference of the SSP parameters (noting that results from \citet{2019ApJ...874..102W} justify the treatment of ISM parameters as latent variables).

In order to explore what effect this simplified treatment of ISM physics has on the inference we now turn to a more complex model of the formation and chemical enrichment of a Milky Way-type galaxy taken from the IllustrisTNG simulations. Note, that by now also the NIHAO simulations \citep{Wang2015, Buck2020,Buck2020c} have implemented \texttt{CHEMPY} supported yield tables including the TNG yield set \citep{Buck2021} and hence would make for a nice dataset for our analysis. However, we have decided to use the exact same galaxy as in \citet{Philcox_2019} for better comparison of our results.

In detail, we use a single galaxy from the $z = 0$ snapshot of the highest-resolution TNG100-1 simulation. We choose a subhalo (index 523071) with mass close to $10^{12}\,\mathrm{M}_\odot$ to select a Milky Way-like galaxy. From this, we extract a set of 1,000 random `stellar particles' from a total of $\sim 40,000$. Each star particle has a mass of $\sim 1.4\times 10^6 \mathrm{M}_\odot$ \citep{2019ComAC...6....2N}. These act as proxies for stellar environments, giving the elemental mass fractions, $\{d_i^j\}$, and cosmological scale factor, $a_i$, at the time of stellar birth. Mass fractions are converted to [X/Fe] abundance ratios using \citet{2009ARA&A..47..481A} solar abundances as in \texttt{CHEMPY}, with the scale-factor ($a_i$) to birth-time ($T_i$) conversion performed using \texttt{astropy} \citep{astropy:2013,astropy:2018},\footnote{\href{http://www.astropy.org}{http://www.astropy.org}} assuming a $\Lambda$CDM cosmology with \citet{planck2015} parameters, as in TNG \citep{2018MNRAS.475..648P}.\footnote{Note, as for the \texttt{CHEMPY} mock data, we exclude any particles with $T_i\notin[2,12.8]\,\mathrm{Gyr}$ to ensure that the true times are well separated from our training age limits, avoiding neural network errors. This removes $\sim5\%$ of the stars.} Observational errors are incorporated as above, giving a full data-set that is identical in structure to the \texttt{CHEMPY} mock data. For more details and a plot of the [Mg/Fe] vs. [Fe/H] plane for this galaxy see Sec.~6.3 and Fig.~5 of \citet{Philcox_2019}.

We note that this TNG galaxy was deliberately chosen by \citet{Philcox_2019} to have both a high-$\alpha$ and low-$\alpha$ chemical evolution sequence to test their inference on a mock galaxy with Milky Way-like properties. There is still some debate on the exact formation of this bimodality but it is generally attributed to gas-rich mergers and different modes of star formation \citep[e.g.][]{2018MNRAS.474.3629G,2018MNRAS.477.5072M,2019MNRAS.484.3476C,Buck2020,Buck2023}. Similarly, in chemo-dynamical models, Milky Way-like bimodalities can also be achieved by a combination of radial migration and selection effects without the need for mergers or starbursts \citep[e.g.][]{2009MNRAS.396..203S,2013A&A...558A...9M,2017ApJ...835..224A}.

We show our inference results for the TNG data set in Fig.~\ref{fig:TNG_N_star_analysis} and Fig.~\ref{fig:CHEMPY_TNG_sim_sbi}, respectively.
Again, we find that inference becomes better with increasing number of stars. Despite the drastic difference in chemical enrichment model between training and testing data, our SBI pipeline is impressively capable of inferring the correct posterior values. SBI results for $\alpha_{\rm IMF}$ are almost perfect while $\log_{10}(N_{\rm Ia})$ is slightly biased low. This is exactly opposite to the results of HMC where inference for $\alpha_{\rm IMF}$ is biased and results for $\log_{10}(N_{\rm Ia})$ are more in agreement. Hence, our SBI inference is on par with the HMC results and given their extreme computational advantage they actually supersede HMC.

Looking at the joint posterior in Fig.~\ref{fig:CHEMPY_TNG_sbi} we see that also in this case SBI recovers the true parameters with less than $3\sigma$ bias.



\section{Discussion}
\label{sec: discussion}

\textcolor{red}{here goes the assumption that stars are iid since each star is produced by a single call to \texttt{CHEMPY}. However, real physics might correlate stars abundances by star formation histories and cumulative enrichment...}

Our study demonstrates that simulation-based inference (SBI) provides a powerful and efficient alternative to conventional methods such as Hamiltonian Monte Carlo (HMC) for inferring global galactic parameters. By leveraging neural density estimators and neural network emulators, we achieved remarkable computational efficiency without compromising precision or accuracy.

The key assumption underpinning our methodology — that individual stars are independently sampled from their respective stellar environments — is foundational for tractability. However, this assumption warrants closer examination. In reality, stellar abundances are correlated due to shared star formation histories, cumulative enrichment, and dynamical interactions. Future efforts should explore methodologies capable of incorporating such correlations to further refine the accuracy of SBI, potentially through hierarchical modeling or graph-based methods.

An exciting avenue for future research involves expanding SBI to directly infer empirical nucleosynthetic yields, which remain a major uncertainty in GCE models. In the current framework, \texttt{CHEMPY} relies on tabulated yields from theoretical studies, which may not fully represent the complex processes driving stellar enrichment. Adapting SBI to simultaneously infer galactic parameters and refine empirical yield tables would require changes to the simulator. Specifically, \texttt{CHEMPY} would need to incorporate parameterized yield modifications as part of its input space, allowing for flexible adjustments to enrichment rates during inference. This would also necessitate larger training datasets and enhanced validation techniques to ensure convergence. Such an approach could provide a unified framework for calibrating galactic models directly against observational data.

Compared to previous HMC-based studies \citep[e.g.][]{Philcox_2019}, our results highlight SBI's resilience to certain types of model misspecification, such as mismatched yield tables. The robustness of SBI in these cases stems from its ability to approximate complex posterior distributions efficiently. Notably, SBI retained high accuracy in scenarios where HMC struggled, particularly for the high-mass slope of the IMF ($\alpha_{\rm ISM}$). This suggests SBI's potential for real-world applications, where the underlying models may deviate from observational data.

The applicability of our method extends to future spectroscopic surveys, such as those planned by the 4MOST or WEAVE consortia, which will provide orders of magnitude more data than current datasets. Our findings indicate that SBI can seamlessly scale to such large datasets, offering significant advantages in terms of speed and computational cost.

Nevertheless, limitations remain. The simplified physics of the \texttt{CHEMPY} model, while advantageous for computational efficiency, omits the complexities of dynamical gas flows, feedback, and metal mixing present in cosmological simulations. While our tests on IllustrisTNG data affirm the robustness of SBI, integrating more sophisticated models into the inference pipeline represents an exciting avenue for future work. On this line of reasoning we refer also to the discussion in \citet{Philcox_2019}.

\section{Summary and conclusions}
\label{sec: conclusion}

This study introduces simulation-based inference (SBI) as an innovative framework for constraining galactic parameters using stellar chemical abundances. By training neural posterior estimators on forward simulations from the \texttt{CHEMPY} model, we achieved precise and accurate inferences for two key parameters: the high-mass slope of the initial mass function ($\alpha_{\rm IMF}$) and the normalization of Type Ia supernova rates ($\log_{10}(N_{\rm Ia})$).

Our results underscore the transformative advantages of SBI over traditional methods like Hamiltonian Monte Carlo (HMC), marking a paradigm shift in galactic parameter inference:
\begin{itemize}
    \item Orders-of-magnitude speed-up: SBI dramatically reduces computational requirements, achieving runtime improvements exceeding 1,000-fold compared to HMC. For instance, while HMC requires $\sim 40\,\mathrm{hours}$ to infer parameters from just 200 stars, SBI completes inference on thousands of stars in mere minutes. This efficiency makes SBI uniquely suited for analyzing the massive datasets expected from next-generation spectroscopic surveys.
    \item Scalability: SBI’s amortized nature allows it to scale seamlessly with the size of the dataset. By training a neural posterior estimator once, the method can be applied repeatedly at virtually no additional computational cost. This scalability is essential for leveraging the millions of stars that future surveys like 4MOST and WEAVE will provide, enabling precise population-level inferences.
    \item Robustness to model misspecifications: Unlike HMC, which shows significant biases when faced with discrepancies between model assumptions and data, SBI demonstrates remarkable robustness. Even under conditions of mismatched yield tables or data generated from hydrodynamical simulations, SBI provides accurate and reliable results. This robustness ensures SBI’s applicability in real-world scenarios where exact model fidelity cannot be guaranteed.
\end{itemize}

In addition to its immediate advantages, SBI lays the foundation for future advancements in galactic modeling. Its flexibility can enable the direct inference of empirical nucleosynthetic yields and facilitate integration with more complex galaxy formation models. These enhancements will further solidify SBI as a cornerstone method in galactic archaeology.

In conclusion, SBI represents a breakthrough in simulation-based analysis, delivering unparalleled speed, precision, and scalability. By overcoming the computational limitations of traditional techniques like HMC, SBI paves the way for extracting deeper insights into the chemical and dynamical evolution of galaxies in the era of massive spectroscopic surveys.



\begin{acknowledgements}
      This project was made possible by funding from the Carl Zeiss Stiftung.
\end{acknowledgements}

% WARNING
%-------------------------------------------------------------------
% Please note that we have included the references to the file aa.dem in
% order to compile it, but we ask you to:
%
% - use BibTeX with the regular commands:
%   \bibliographystyle{aa} % style aa.bst
%   \bibliography{Yourfile} % your references Yourfile.bib
%
% - join the .bib files when you upload your source files
%-------------------------------------------------------------------

\bibliographystyle{aa}
\bibliography{bib.bib}


\begin{appendix}

\section{Code and Data Availability}
\label{sec:appendix_code_and_data}

To facilitate a wider community's usage and contributions, we make use of the reproducibility software
\href{https://github.com/showyourwork/showyourwork}{\showyourwork}
\citep{Luger2021}, which leverages continuous integration to
programmatically download the data from
\href{https://zenodo.org/}{zenodo.org}, create the figures, and
compile the manuscript. Each figure caption contains two links: one
to the dataset stored on zenodo used in the corresponding figure,
and the other to the script used to make the figure (at the commit
corresponding to the current build of the manuscript). The git
repository associated to this study is publicly available at
\url{https://github.com/TobiBu/sbi-chempy}, and the release
v0.4.1 allows anyone to re-build the entire manuscript including rerunning all analysis. The datasets and neural network weights are stored at \url{https://doi.org/10.5281/zenodo.7343715} \textcolor{red}{change to final zenodo dataset!}.

\begin{figure*}[]
     \centering
     \includegraphics[width=\textwidth]{figures/sbc_rank_plot_NPE_C.pdf}
     %\vspace{-.5cm}
     \caption{SBC ranks of ground truth parameters under the inferred posterior samples for each of the six parameters (red bars). The grey area shows the 99\% confidence interval of a uniform distribution given the number of samples provided.}
     \label{fig:sbc}
     \script{evaluate_sbi.py}
\end{figure*}

\begin{figure}[]
     \centering
     \includegraphics[width=\columnwidth]{figures/tarp_plot_NPE_C.pdf}
     %\vspace{-.5cm}
     \caption{TARP plot showing the expected coverage probability vs. the credibility level $\alpha$. The dashed black 1:1-line shows an ideal calibrated posterior and the blue solid line shows the TARP value for our NPE.}
     \label{fig:tarp}
     \script{evaluate_sbi.py}
\end{figure}

\begin{figure*}[]
     \centering
     \includegraphics[width=\textwidth, trim={6cm, 0cm, 6cm, 0cm}, clip]{figures/ili_coverage.pdf}
     \includegraphics[width=\textwidth, trim={6cm, 0cm, 6cm, 0cm}, clip]{figures/ili_predictions.pdf}
     %\vspace{-.5cm}
     \caption{Top: TARP plot showing the expected coverage probability vs. the credibility level $\alpha$ for each of the six individual parameters in our inference. The dashed black 1:1-line shows an ideal calibrated posterior and the blue solid line shows the TARP value for our NPE. Bottom: }
     \label{fig:tarp}
     \script{evaluate_sbi.py}
\end{figure*}
% The ... repository, which contains code, additional documentation, and interactive dashboards, is available on GitHub.%\footnote{URL: \url{https://github.com/bGuenes/sbi_chemical_abundances}}

\section{Neural Posterior Calibration}
\label{sec:sbc}

Since SBI relies in neural networks to approximate posterior densities one important point is to check that neural network hyperparameters are well chosen and that posterior estimates are trustable.

After a density estimator has been trained with simulated data to obtain a posterior, the estimator should be made subject to several diagnostic tests. This needs to be performed before being used for inference given the actual observed data. Posterior Predictive Checks provide one way to "critique" a trained estimator based on its predictive performance. Another important approach to such diagnostics is simulation-based calibration as developed by \citet{Cook2006} and \citet{Talts2018}. 

\paragraph{Simulation-based calibration}
Simulation-based calibration (SBC) provides a (qualitative) view and a quantitive measure to check, whether the variances of the posterior are balanced, i.e. it is neither over-confident nor under-confident. As such, SBC can be viewed as a necessary condition (but not sufficient) for a valid inference algorithm: If SBC checks fail, this tells you that your inference is invalid. If SBC checks pass, this is no guarantee that the posterior estimation is working.

To perform SBC, we sample some $\theta_i^o$ values from the parameter prior of the problem at hand and simulate "observations" from these parameters: 
\begin{equation}
    x_i = \text{simulator}(\theta_i^o)
\end{equation}
Then we perform inference given each observation $x_i$ which produces a separate posterior $p_i(\theta|x_i)$ for each $x_i$. The key step for SBC is to generate a set of posterior samples $\{\theta\}_i$ from each posterior. We call this $\theta_i^s$, referring to $s$ samples from the posterior $p_i(\theta|x_i)$. Next, we rank the corresponding $\theta_i^o$ under this set of samples. A rank is computed by counting how many samples $\theta_i^s$ fall below their corresponding $\theta_i^o$ value \citep[see section 4.1 in][]{Talts2018}. These ranks are then used to perform the SBC check itself.

The core idea behind SBC is two fold: (i) SBC ranks of ground truth parameters under the inferred posterior samples follow a uniform distribution (If the SBC ranks are not uniformly distributed, the posterior is not well calibrated); and (ii) samples from the data averaged posterior (ensemble of randomly chosen posterior samples given multiple distinct observations $x_o$) are distributed according to the prior.

Hence, SBC can tell us whether the SBI method applied to the problem at hand produces posteriors that have well-calibrated uncertainties, and if the posteriors have uncalibrated uncertainties, SBC surfaces what kind of systematic bias is present: negative or positive bias (shift in the mean of the predictions) or over- or under-dispersion (too large or too small variance).

In the left panel of Fig.~\ref{fig:sbc} we show the distribution of ranks (depicted in red) in each dimension. Highlighted in grey, you see the 99\% confidence interval of a uniform distribution given the number of samples provided. In plain english: for a uniform distribution, we would expect 1 out of 100 (red) bars to lie outside the grey area. This figure shows that overall our posteriors are decently calibrated. Only for the parameter $\log_{10}\left(\mathrm{SFE}\right)$ we see a single bar outside the 99\% confidence interval. But most importantly for the parameters of interest here, $\log_{10}\left(N_\mathrm{Ia}\right)$ and $\alpha_\mathrm{IMF}$ we have a well calibrated posterior.

\paragraph{Tests of Accuracy with Random Points (TARP)}

TARP \citep{Lemos2023} is an alternative calibration check for the joint distribution, for which defining a rank is not straightforward. Given a test set $(\theta^*,x^*)$ and a set of reference points $\theta_r$, TARP calculates statistics for posterior calibration by - drawing posterior samples $\theta$ given each observation $x^*$ and calculating the distance $r$ between $\theta^*$ and $\theta_r$ counting for how many of the posterior samples the distance to $\theta_r$ is smaller than $r$ \citep[see e.g. Fig.~2 in][for an illustration]{Lemos2023}.

For each given coverage level $\alpha$, one can then calculate the corresponding average counts and check, whether they correspond to the given $\alpha$. The visualization and interpretation of TARP values is therefore similar to that of SBC. However, in contrast to SBC, TARP provides a necessary and sufficient condition for posterior accuracy, i.e., it can also detect inaccurate posterior estimators. In Fig.~\ref{fig:tarp} we show the result for our NPE in blue in comparison to the ideal line shown in black dashed style. This figure clearly shows that our NPE is well calibrated.

Note, however, that this property depends on the choice of reference point distribution: to obtain the full diagnostic power of TARP, one would need to sample reference points from a distribution that depends on $x$. Thus, in general, it is recommended using and interpreting TARP like SBC and complementing coverage checks with posterior predictive checks.

\section{Additional inference results}

% \begin{figure*}
%     \centering
%     \includegraphics[width=\textwidth]{figures/Nstar_comp_different_prior.pdf}
%     \vspace{-.5cm}
%     \caption{Same as Fig.~\ref{fig:CHEMPY_TNG_N_star_analysis} but for mock data a created with parameters for $\alpha_{IMF}$ and $\log_{10}(N_{Ia})$.}
%     \label{fig:N_star_analysis_different_prior}
%     \script{additional_inference.py}
% \end{figure*}

\end{appendix}

\end{document}


%%%% End of aa.dem

